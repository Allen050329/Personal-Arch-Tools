# Maintainer: Zenphyrnix <zenphyrnixcloud@proton.me>
pkgname='python-pytorch-uvm-git'
_pkgname='pytorch'
_pkgver=2.99.99
pkgver=2.99.99
pkgrel=1
pkgdesc='Tensors and Dynamic neural networks in Python with strong GPU acceleration'
arch=('x86_64')
url='https://pytorch.org'
license=('BSD')
depends=(
  'ffmpeg'
  'gflags'
  'gcc12'
  'google-glog'
  'leveldb'
  'lmdb'
  'opencv'
  'openmp'
  'protobuf'
  'pybind11'
  'python-future'
  'python-numpy'
  'python-yaml'
  'qt6-base'
  'zeromq'
  'cuda'
  'nccl'
  'magma-cuda'
  'cudnn'
  'python-typing_extensions'
  'numactl'
  'python-jinja'
  'python-networkx'
  'python-filelock'
  'python-sympy'
)
makedepends=(
  'cmake'
  'doxygen'
  'git'
  'python-setuptools'
)
source=(
  "${_pkgname}-uvm::git+https://github.com/Allen050329/pytorch-uvm.git#branch=uvm"
  '87773.patch'
)
sha512sums=('SKIP'
            '4cd3615ef664ae8e9d584a975e7368f1e4dc557c524850bad420932502c4567fbca0add5f34a65d31ba40796fe3f6698a0f1e74eb39e8b8c12230661e3036a5f')

prepare() {
  cd "${_pkgname}-uvm"

  # This is the lazy way since pytorch has sooo many submodules and they keep
  # changing them around but we've run into more problems so far doing it the
  # manual than the lazy way. This lazy way (not explicitly specifying all
  # submodules) will make building inefficient but for now I'll take it.
  # It will result in the same package, don't worry.
  git submodule sync
  git submodule update --init --recursive

  # Fix building against glog 0.6
  patch -Np1 -i "${srcdir}/87773.patch"

  # https://github.com/pytorch/pytorch/issues/26555
  sed -i 's#^  ${CMAKE_CURRENT_SOURCE_DIR}/tensor_iterator_test.cpp##g' aten/src/ATen/test/CMakeLists.txt

  # Fix build with Python 3.8
  # https://github.com/pytorch/pytorch/issues/28060
  find -name '*.cpp' -exec sed -i '/tp_print/s/nullptr/0/' {} +

  # protobuf 23 requires C++17
  find -name CMakeLists.txt | xargs sed -e 's|CXX_STANDARD 14|CXX_STANDARD 17|' -e 's|CXX_STANDARD 11|CXX_STANDARD 17|' -i

  # Fix cmake prefix path (FS#78665)
  sed -i "s|cmake_prefix_path = _osp.*|cmake_prefix_path = '/usr/lib/cmake'|g" torch/utils/__init__.py

}

build() {
  cd "${srcdir}/${_pkgname}-uvm"

  # Check tools/setup_helpers/cmake.py, setup.py and CMakeLists.txt for a list of flags that can be set via env vars.
  compute_cap=$(nvidia-smi --query-gpu=compute_cap --format=csv,noheader) # TODO: Fix for people who have GPUs with different compute capabilities in the same machine
  if (( $(echo "$compute_cap > 5.99" |bc -l) )); then
    TORCH_CUDA_ARCH_LIST="$compute_cap;$compute_cap+PTX" BUILD_BINARY=ON BUILD_CAFFE2_OPS=OFF BUILD_CAFFE2=OFF BUILD_CUSTOM_PROTOBUF=ON BUILD_DOCS=ON BUILDING_WITH_TORCH_LIBS=ON BUILD_JNI=OFF USE_CUSPARSELT=1 BUILD_NAMEDTENSOR=ON BUILD_SHARED_LIBS=ON BUILD_FUNCTORCH=ON BUILD_NVFUSER=ON BUILD_TEST=OFF CAFFE2_STATIC_LINK_CUDA=OFF CUDA_HOME=/opt/cuda CUDAHOSTCXX=/usr/bin/g++-12 CUDNN_INCLUDE_DIR=/usr/include CUDNN_LIB_DIR=/usr/lib PYTORCH_BUILD_NUMBER=1 TORCH_NVCC_FLAGS="-Xfatbin -compress-all" USE_CAFFE2_OPS=OFF USE_CUPTI_SO=ON USE_FLASH_ATTENTION=1 USE_MEM_EFF_ATTENTION=1 CC=/usr/bin/gcc CXX=/usr/bin/g++ USE_DISTRIBUTED=ON USE_FBGEMM=ON USE_FFMPEG=ON USE_LEVELDB=ON USE_LITE_PROTO=OFF USE_LMDB=ON USE_NATIVE_ARCH=ON USE_NNPACK=ON USE_NUMPY=ON USE_NVRTC=ON USE_OPENCV=ON USE_OPENMP=ON USE_QNNPACK=ON USE_ROCM=OFF USE_STATIC_NCCL=OFF USE_SYSTEM_EIGEN_INSTALL=ON USE_SYSTEM_NCCL=ON USE_TBB=ON USE_ZMQ=ON USE_ZSTD=ON USE_TENSORPIPE=ON VERBOSE=1 USE_CUDA=ON USE_CUDNN=ON USE_NCCL=ON CXXFLAGS="$CXXFLAGS -Wfatal-errors -w -fpermissive -std=gnu++17" CFLAGS="$CFLAGS -Wfatal-errors -w -fpermissive" python setup.py build || TORCH_CUDA_ARCH_LIST="$compute_cap;$compute_cap+PTX" BUILD_BINARY=ON BUILD_CAFFE2_OPS=OFF BUILD_CAFFE2=OFF BUILD_CUSTOM_PROTOBUF=ON BUILD_DOCS=ON BUILDING_WITH_TORCH_LIBS=ON BUILD_JNI=OFF USE_CUSPARSELT=1 BUILD_NAMEDTENSOR=ON BUILD_SHARED_LIBS=ON BUILD_FUNCTORCH=ON BUILD_NVFUSER=ON BUILD_TEST=OFF CAFFE2_STATIC_LINK_CUDA=OFF CUDA_HOME=/opt/cuda CUDAHOSTCXX=/usr/bin/g++-12 CUDNN_INCLUDE_DIR=/usr/include CUDNN_LIB_DIR=/usr/lib PYTORCH_BUILD_NUMBER=1 TORCH_NVCC_FLAGS="-Xfatbin -compress-all" USE_CAFFE2_OPS=OFF USE_CUPTI_SO=ON USE_FLASH_ATTENTION=1 USE_MEM_EFF_ATTENTION=1 CC=/usr/bin/gcc CXX=/usr/bin/g++ USE_DISTRIBUTED=ON USE_FBGEMM=ON USE_FFMPEG=ON USE_LEVELDB=ON USE_LITE_PROTO=OFF USE_LMDB=ON USE_NATIVE_ARCH=ON USE_NNPACK=ON USE_NUMPY=ON USE_NVRTC=ON USE_OPENCV=ON USE_OPENMP=ON USE_QNNPACK=ON USE_ROCM=OFF USE_STATIC_NCCL=OFF USE_SYSTEM_EIGEN_INSTALL=ON USE_SYSTEM_NCCL=ON USE_TBB=ON USE_ZMQ=ON USE_ZSTD=ON USE_TENSORPIPE=ON VERBOSE=1 USE_CUDA=ON USE_CUDNN=ON USE_NCCL=ON CXXFLAGS="$CXXFLAGS -Wfatal-errors -w -fpermissive -std=gnu++17" CFLAGS="$CFLAGS -Wfatal-errors -w -fpermissive" python setup.py build
  else
    echo "Compute capability $compute_cap is less than 6.0, which means it doesn't support UVM. Please use normal pytorch."
    sleep 3
    exit 1
  fi

}

_package() {
  # Prevent setup.py from re-running CMake and rebuilding
  sed -e 's/RUN_BUILD_DEPS = True/RUN_BUILD_DEPS = False/g' -i setup.py

  python setup.py install --root="${pkgdir}"/ --optimize=1 --skip-build

  install -Dm644 LICENSE "${pkgdir}/usr/share/licenses/${pkgname}/LICENSE"

  pytorchpath="usr/lib/python$(python -c 'import sys; version = ".".join(map(str, sys.version_info[:2])); print(version)')/site-packages/torch"
  install -d "${pkgdir}/usr/lib"

  # put CMake files in correct place
  mv "${pkgdir}/${pytorchpath}/share/cmake" "${pkgdir}/usr/lib/cmake"

  # put C++ API in correct place
  mv "${pkgdir}/${pytorchpath}/include" "${pkgdir}/usr/include"
  mv "${pkgdir}/${pytorchpath}/lib"/*.so* "${pkgdir}/usr/lib/"

  # clean up duplicates
  # TODO: move towards direct shared library dependecy of:
  #   c10, caffe2, libcpuinfo, CUDA RT, gloo, GTest, Intel MKL,
  #   NVRTC, ONNX, protobuf, libthreadpool, QNNPACK
  rm -rf "${pkgdir}/usr/include/pybind11"

  # python module is hardcoded to look there at runtime
  ln -sf /usr/include "${pkgdir}/${pytorchpath}/include"
  find "${pkgdir}"/usr/lib -type f -name "*.so*" -print0 | while read -rd $'\0' _lib; do
    ln -sf ${_lib#"$pkgdir"} "${pkgdir}/${pytorchpath}/lib/"
  done
}

package() {
  pkgdesc='Tensors and Dynamic neural networks in Python with strong GPU acceleration (with CUDA and MKL-DNN)'
  conflicts=(python-pytorch python-pytorch-cuda python-pytorch-git)
  provides=(python-pytorch=${pkgver} python-pytorch-cuda=${pkgver})

  cd "${srcdir}/${_pkgname}-uvm"
  _package
}
